version: 1.0.8

endpoints:
  custom:
    # ── Ollama (unchanged) ───────────────────────────
    - name: "Ollama"
      apiKey: "ollama"
      baseURL: "http://ollama:11434/v1"
      models:
        default: ["mistral"]
        fetch:   true
      titleConvo: true
      titleModel: "current_model"
      summarize:  false
      modelDisplayLabel: "Ollama"

    # ── LangGraph proxy ──────────────────────────────
    - name: "LangGraph"
      apiKey: "proxy"
      baseURL: "http://langchain:8082/v1"   # ← add /v1
      directEndpoint: false                # let LC add /models & /chat/completions

      models:
        default: ["openchat"]              # placeholder
        fetch:   true                      # LibreChat → GET /v1/models

      titleConvo: true
      titleModel: "current_model"
      summarize:  false
      modelDisplayLabel: "LangGraph"
